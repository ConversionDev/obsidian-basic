- 확실히 알아두면 만사가 편해지는 머신러닝 10가지 알고리즘
	- https://yozm.wishket.com/magazine/detail/1931/
	- 엑셀파일이 정형 데이터, 한글/이미지 등이면 비정형 데이터
	- 이 10가지 중 팀 방식에 필요한 알고리즘을 판단하는 것은 사람 몫
	- 데이터 전처리 후 터미널에 뜨는 것은 속성에 해당하는 것. 그래서 10대 알고리즘 중 하나를 선택해서 기능을 붙여주면 모델이 되면서 생존률 맞히는 걸 하게 하는 것. 이후 훈련을 해서 평가를 하는 것임.
	- 사실 10개 중 하나를 선택하는 걸 사람이 해야하는데 어려우면 그냥 10개 다 붙이고 점수 제일 잘 나온거를 쓰긴 함

1. 선형 회귀
	- 선형회귀모델은 연속형(레이쇼, 인터벌만 가능. 범주형은 불가능)
	- 타이타닉에는 일단 범주형만 있다고 생각하면 선형회귀를 쓸 수 없으니까 로지스틱을 써라.
2. 로지스틱 회귀
	- 알고리즘 10개 중 8개가 지도학습에 대한 지도학습에 대한 모델이고 2개가 비지도학습에 대한 모델임
		- 비지도의 2개 중 하나는 연속형을 쓸거고 나머지 하나는 범주형을 쓰겠네?
		- 나머지 8개 중 4개는 연속형일 테고 나머지 4개도 범주형을 쓰겠네?
		- 그러면 어떤 모델이 적합하다 판단할 때 지도 비지도를 먼저 나눠보면 8개로 추려지고, 그 중에서 연속형이냐 범주형이냐에 따라서 또 4개로 줄어드니까 10개를 다 쓰지 않는 것
3. 최근접 이웃 (KNN)
	- 현재 값에서 어느정도 구간 안에서는 큰 변동이 없을 것이라는 느낌
	- 최근접이웃에서는 아웃라이어에 취약함
		- 아웃라이어: 평균값을 외곡시킬 수 있는 정도의 이례적인 값. 
		- 그래서 나중에 95% /  +- 상위 2.5%와 하위 2.5%는 제외하라는 프롬프트를 줘야 함
		- DS에서 아웃라이어는 제외해줘 --> 라는 프롬프트 주는 게 좋아
4. 나이브 베이즈 (NB 라고 부름)
	- 조건부 확률
	- 
5. 결정 트리 = 스무고개
	- 결정과 약간 상반되는, 대응하는 말이 랜덤
	- 나무에 대응하는 말이 숲
	- 트리가 무한히 깊어질 경우 오버피팅 될 수 있음
		- 오버피팅 : 너무 잘 맞춘 경우. 그럴리가 없는데... 가우스가 세상 모든 것은 100%가 있을 수 없다고 했음
6. 랜덤 포레스트, 결정 트리랑 약간 반대?, 숲 안에 나무가 있어
7. 몰라도 되고
8. 라이트 GBM = LGNM --> 이거 알아야 해
	- 나무 100개를 각각 다 입력해서 60개 이상이면 결정하는 식


- 타이타닉 예제에서는 다음 다섯가지를 써 볼 예정임. EVALUATE 도 사진처럼 수정
		![[Pasted image 20251209164846.png]]


- GPT, SONET)) @titanic_service.py (93-119) 여기에서 모델링에 주석된 알고리즘으로 this, train 을 결합하여 러닝과 평가까지 이어서 작성해주고, @titanic_router.py 여기에서 @titanic_router.py (191-196) 이 주석대로 처리하고싶으니까 전략을 작성해줘. 실행하지는 말고

- 라우터 파일 맨 밑에 SUBMIT 메핑 적어줌
- CURSOR) @titanic_router.py (278-282) (위에서 적은 부분) 이걸 실행하면 @download 여기에 케글에 제출할 csv 파일을 정확도가 가장 높은 random_forest 와 결합한 내용으로 된 파일을 저장해줘
- 포스트맨에서는 보이는데 @download 여기 폴더에 파일이 안 생겼어. 왜그런거야?
