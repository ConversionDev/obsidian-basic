- 아이스크림은 도커 안에다가 시스아웃 하는거고, 목적은 리액트에 보이는 것임
- GPT) 지도학습에서 train과 더불어있는 test 의 셋의 역할은 무엇인가? 
	- test 세트는 DS라고 생각해
	- **train set**: 모델이 학습하는 데이터
	- **test set**: 학습이 끝난 모델이 **처음 보는 데이터**로 성능을 평가하는 용도
- GPT) 타이타닉 예제를 하는데, train.csv 를 전처리과정을 통해 내부 데이터를 전부 int 로 변경하였어. 이것과 머신러닝에서 모델과의 관계를 설명해줘. 나는 이 모델을 만들고싶어
	- 어제 한 거 = 정제했다 라고 함
	- 모델이 학습하는 것은 원본 데이터가 아니라 내가 설계한 feature 들임. 따라서 전처리가 곧 모델의 성능을 결정함. 이게 전처리가 모델보다 중요하다고 하는 이유임
	- 모델을 만들고싶다 는 말의 단계
		1. ==전처리 파이프라인==: 어제 만든게 메서드 연결했기 때문에 파이프라인 연결한거임
			- 1단계 결과 = 피처셋 = DF
		2. ==모델== (러닝 모델) (LogisticRegression, RandomForest 등 이미 존재하는, 그래서 우리가 만드는 건 아님)
		3. ==학습(train)==
		4. ==평가(test)==
	- 전처리된 train.csv(int 형태)와 머신러닝 모델의 관계
		- 1) 왜 전처리가 필요한가?
			- 머신러닝 모델은 숫자(int/float)만 이해한다
			- 따라서 성별, 탑승항구 같은 문자열을 모두 숫자로 바꾸는 과정이 필수다.  
				- → 전처리는 “데이터를 기계가 이해할 수 있는 형태로 번역하는 과정”.
	    - 2) 전처리된 train.csv = 모델의 입력 데이터
		    - feature(X): Pclass, Gender, Age, Fare 등
		    - label(y): Survived (0/1)
		    - 이 구조가 **지도학습 모델이 요구하는 표준 형태**다.
		- 3) 모델은 이 숫자 패턴을 학습한다**
		- 예:
			- Gender=1 → 생존 확률 ↑
			- Pclass=3 → 생존 확률 ↓
			- Age가 낮을수록 생존 확률 ↑
			- 모델은 이러한 관계를 수학적으로 학습한다.
		- 4) 전처리가 모델 성능을 결정한다
			- int 변환
			- 결측치 처리
			- 범주형 인코딩
			- binning, scaling 등
		👉 전처리 품질이 모델 품질을 직접 결정한다.  
		“좋은 전처리 = 좋은 모델”.

- 범주형=카테고리=노미널, 오디널=인트로 떨어짐=0과 1사이 없음?
- 연속형=컨티뉴=인터벌, 레이쇼=float로 떨어짐=0과 1사이 무수히 많음?

- ~함수들은 RAW 데이터(DS) -> feature space (DF)로 변환함 -> int 로 바꿈
	- int에서 다시 DF 로 갈 수 없음 (불가역성)
	- 기본 메서드들에 해당하는 부분 안에서는 수정 가능하지만, 어제 했던 부분들부터는 수정 안 됨. int로 변하는 부분이니까

- GPT) 인공지능에서 파인튜닝은 무엇인가?
	- 기존에 있던 모델들을 입맛에 맞게 수정하는 것

- 타니타닉에서 train과 test 를 합쳐야 DS가 됨
- accuracy(정확도라고 하지않고 어류케시라고 많이 부름) : 타이타닉에서도 train과 test 파일이 7:3비율로 train을 나눔
- GPT한테 팀꺼 CSV 파일을 train 과 test 를 7:3 정도로 나눠줘 하기
- 정확도가 90% 이상이여야 판매할 수 있다고 생각하지만, gpt도 60-70%정도 되려나.. 그러니까 우리가 만드는 시스템들도 정확도가 낮아도 용인되는 시대인 것임

### 서비스 파일 수정: 어제는 트레인만 했고, 오늘 테스트까지 붙여서 전처리
- ic(=sysout)은 컴퓨터한테 부담이 안 되기 때문에 트레인이랑 테스트 ic 따로 처리 시작과 완료로 나눠서 복붙해줌
	![[Pasted image 20251209105057.png]]

- (튜플) 불변
- [리스트] 가변

- 메소드에서 drop_features 부분이랑 check_null 부분 아래처럼 간결하게 바꿔줌
	-![[Pasted image 20251209125711.png]]
	- axis : 축
		- axis가 1이면 세로방향으로 연산해라 , 0이면 가로방향으로 연산해라
		- 그래서  drop_features에서는 열 1개를 삭제하는 일이 있으니까 axis가 1인 것.




- 추가될 때 마다 다음 부분을 수정하지 않으려면
	 ![[Pasted image 20251209131627.png]]
- 다음 부분에만 추가해주면 됨
		![[Pasted image 20251209131655.png]]