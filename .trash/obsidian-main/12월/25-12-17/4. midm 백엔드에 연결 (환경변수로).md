midm을 백엔드에 연결하도록 옵션을 추가했습니다. 이제 환경변수로 전환할 수 있습니다.

변경사항

- backend/app/service/midm_llm.py 새로 추가: build_midm_llm(model_path=None, max_new_tokens=256) → 로컬 Mi:dm 체크포인트를 LangChain용 HuggingFacePipeline으로 반환.

- backend/app/main.py LLM 초기화 로직 수정:

- USE_MIDM=1이면 MIDM_PATH(없으면 기본 backend/app/model/midm)에서 로컬 Mi:dm을 로드.

- 그 외에 OPENAI_API_KEY가 있으면 OpenAI 사용.

- 둘 다 없으면 retrieval-only.

- backend/requirements.txt에 transformers>=4.38.0 추가.

사용 방법

1) 로컬 모델 경로가 기본 위치(지금 올려둔 backend/app/model/midm)라면:

- USE_MIDM=1 설정 후 백엔드 기동.

2) 다른 경로를 마운트했다면:

- USE_MIDM=1 MIDM_PATH=/app/backend/app/model/midm 등으로 지정.

3) 프런트는 그대로 3000번 → /api/chat 호출. 백엔드에서 midm이 활성화되어 있으면 midm으로 응답합니다.

도커 예시 (docker-compose 환경변수에 추가):

environment:

  USE_MIDM: "1"

  MIDM_PATH: "/app/backend/app/model/midm"   # 컨테이너 내 경로

참고

- 기존 OpenAI 경로는 유지되어 필요 시 USE_MIDM만 끄면 다시 OpenAI/Fake 흐름으로 돌아갑니다.

- 모델 파일이 크므로 도커에서는 볼륨 마운트를 권장합니다(이미지로 COPY하지 않기).


----

powershell (36-111) --> 만약 이 오류가 pgvector 가 없어서 나는 오류라면, 의존성을 제거해주고 지금은 랭체인만 연결해줘. 만약 에러 원인이 이게 아니라면 아무것도 수정하지말고 답변만 알려줘

이건 pgvector 부족이 아니라 DB 호스트 이름(postgres)을 못 찾는 문제입니다. 로컬에서 python -m backend.app.main을 돌리면 POSTGRES_CONNECTION_STRING이 postgres://...@postgres:5432/...로 설정되어 있어 컨테이너 내부 네트워크의 호스트명 postgres를 찾지 못해 실패합니다. 코드/의존성은 건드리지 않아도 되고, 해결하려면 둘 중 하나를 선택하세요:

- 로컬 DB/컨테이너를 올리고, 호스트를 localhost나 실제 IP로 바꾼 뒤 실행

- 예: POSTGRES_CONNECTION_STRING=postgresql://langchain:langchain@localhost:5432/langchain

- 도커-compose 환경에서 실행

- docker-compose up -d로 postgres 서비스가 떠 있는 상태에서 API를 기동

요약: pgvector 의존성 제거가 필요한 상황은 아니며, DB 호스트 경로만 맞추면 됩니다.