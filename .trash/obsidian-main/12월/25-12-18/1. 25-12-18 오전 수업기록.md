- 오늘은 미듬 훈련 시작

- GPT의 파운데이션모델은 트렌스포머
- 알파카의 파운데이션 모델은 라마
- 라마의 파운테이션 모델은 트렌스포머
- 라마의 업데이트 버전이 알파카

- 트렌스포머와 지피티의 차이: 트랜스포머는 읽기만 가능한데 지피티는 읽기뿐만 아니라 쓰기가 가능
- 라마는 이미 쓰기까지 가능한데, 라마와 지피티의 차이는 지피티는 공개가 안되어있어서 파인튜닝이 안 되고 돈도 써야하는데 라마는 공개되어있어서 무료이고 파인튜닝까지 가능
- 지금 쓰는 모델은 모델이다. 
- 모델의 집합은 시리즈
- 터미네이터에 나오는 600,700 같은 것들을 각각 모델이라고 하고, 알파카의 파운데이션 모델인 라마도 모델이고, 패션 모델의 모델 --> 이 세 가지를 모두 모델이라고 하는데 무슨 공통점이 있을까?
	- ==모델이란 데이터를 담고 정해진 동선만 다니는 것==
		- 파이프라인만 다닐네고
		- 모델은 프로토콜을 가짐.
		- 모델의 기능 : 프로토콜을 가지고 데이터를 정해진 길로 다니는 것


정수로 만들면 0과 1 중 하나로 만드는 게 양자화 - > 큐로라
튜닝하고싶은 부분만 = 어뎁터를 붙인 데만 살고 나머지는 프리즈 된 게 - > 로라
페프트는 로라와 큐로라를 아우르는 기술을 뜻함
좋은건 로라인데(파라미터 안 줄였으니까), 제약이 크니까 큐로라


자바모델은 왔다갔다만 하고 내가 만들었는데, 레그에서 모델은 왔다갔다하면서 학습을 하고 만들어진걸 씀
- 학습할 때 라우터에 3개 필요함. chat/rag/training 사용자가 질문한 내용에 대해서 답변하는 게 챗, 학습하는 게 트레이닝 / 채팅을 서빙이라 하고, 트레이닝이 학습
- 자바에서 스레드 = 레그에서 인보크 / 자바에서 ??? = 레그에서 배치
- 어씽크로 해야하니까 a인보크

자바와의 차이는 자바는 원트랙, 레그는 투트랙

- 라우터
	- 라우터의 레그 라우터에서 템프러쳐는 창의성을 뜻함. 보통 0~2 사이로 설정하며 답맞출 땐 0에 가깝고 리뷰작성은 2에 가까운 것. 
	- 템프러처는 관리자모드에서 설정하는 것임
- 서비스
	- 서비스의 레그서비스는 벡터디비까지 왔다갔다 하는 애?
	- 서비스의 챗, 레그는 서빙 / 소비자가 대화를 원할 때 답변하는 것이 서빙
	- 서비스의 임베딩과  트레이닝이 학습용
	- ingest: 수집 / embedding: 삽입하다
		- ingest 데이터는 기존에 내가 data 폴더에 두는 데이터 외에 바깥 데이터를 뜻함

- 서빙으로 길을 만들어줘야 모델이 동선을 제약받아서 훈련할 수 있는 것

- 기존에는 프론트가 임의 경로를 백에 만들어서 했었는데 이제는 훈련을 위해서 서빙과 트레이닝의 경로를 우리가 만들어줘야 하니까 기존에 임의적으로 만들어진 백과 연결된 uri를 찾아서 백에 어디 파일에 있는지 찾아
		![[Pasted image 20251218121943.png]]
	- main.py에 있었음. 그 부분만 긁지말고 파일 자체를 커서한테 주면서 다음 프롬프트 주기
		-  ==CURSOR)== @backend/app/main.py 여기에 있는 라우팅을 @backend/app/router/chat_router.py 여기로 옮겨줘
	- 미듬 모델과 챗팅하는 RAG 에 필요한 패키지 . 도커로 돌리는 것이 아닌, 로컬 실행시 터미널에 직접 설치해야 합니다. 다음 내용 터미널에서 실행
		pip install "transformers>=4.40.0" "datasets" "accelerate" "bitsandbytes" "peft" "trl"
	- 미듬 모델과 서비스랑 연결하기 위해서 / 챗-서비스에 다음 내용 임포트하기
		import torch 
		from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig
	- ==CURSOR)== @backend/app/service/chat_service.py 여기에 임포트된 클래스를 활용해서 peft의 큐로라방식으로 대화하고, 학습하는 코드를 추가해줘.
- GPR) AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig 가 뭐야?
	- @backend/app/router/chat_router.py 여기의 @chat_router.py (36-64) 이 메소드를 호출할 때 @backend/app/service/chat_service.py 여기에 로드된 모델과 대화하도록 해줘
	- CURSOR) @backend/app/service/chat_service.py 여기에 임포트된 클래스를 활용해서 peft의 큐로라방식으로 대화하고, 학습하는 코드를 추가해 --> 아까 준 명령을 보면 rora가 아니라 Qrora라니까.@chat_service.py (278-279) 여기 보면 지금 로라로 된거지? 큐로라로 수정해줘
	- 