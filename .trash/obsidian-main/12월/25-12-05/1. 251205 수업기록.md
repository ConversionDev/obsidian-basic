- 스파크 책 p.26
	- 용어정리
		- 애플리케이션: API를 써서 스파크위에서 돌아가는 사용자 프로그램. 핵심은 I 가 인터페이스라는 것. 중간에 껴있는 것. 화면은 인터페이스만 보고 안에 내용은 볼 수 없는 것. 메뉴판 같은 것
		- Session: 코어기능들과 상호 작용할 수 있는 진입점(=URI)=엔드포인트)을 제공하며 그 API로 프로그래밍 할 수 있게 해주는 객체.
			- 여기서 코어는 로그인을 포함하지 않음. 로그인은 하나의 시스템을 위해 존재하는 핵심이지 로그인은 그 핵심이 존재하기 위한 부가적인 요소일 뿐이기 때문 
		- 잡 job : 태스크의 집합. 액션( = 메서드 = save( ):CRUD, collect( ) ) 에 대한 응답으로 생성되는 여러 태스크로 이루어진 병렬 연산.   즉, 태스크를 하기 위한 액션
		- 스테이지 stage
		- 태스크 task
	- 잡이 더 큰 개념
	- 머신러닝에도 파이프라인이 있다
- 깃허브에서도 액션과 스테이지가 있음(잡은 없음)

**잡(메트릭스. 액션의 집합) - 액션(테스크의 집합. 리스트. 파이프라인 하나) - 테스크

- 깃허브에서 액션은 CI CD를 해준다
	- CI : 자동으로 코드(피처)를 합칠 때마다 검사해주는 시스템. 머지랑 에러 해결을 자동으로 하는 것 
	- CD : 테스트 통과 후 배포까지 해주는 시스템. 브라우저에 쏘는 것
- 깃허브에서 액션이 파이프라인 하나를 의미
	- 메소드 save ( ) 하나로 컨서레엔 전체에 다 같은 이름으로 저장되니까 그 파이프라인 1개가 액션이다
- 잡 = 여러개의 파이프라인
- 스테이지 : 컨서레엔 하나 하나의 공간
- step 스텝 : 컨-서-레-엔 순서로 하나씩 이동하는 것
- 결국 프롬프트 줄 때는, ~잡에서 ~액션에서 ~스테이지에서 ~테스크를 실행해달라고 하게 되겠지 

-----------------
### 타이타닉 코드
- ai 밑에 타이타닉 서비스였던거 ml서비스로 이름 바꾸고 사진처럼 구조 바꿈
	- 모델이 디티오, 라우터가 컨트롤러. 지금은 cs로 직접 정보 넣어주니까 데이터를 따로 디비에 저장할 필요 없어서 레파지토리 필요 없는 것
	- 회사) 모델 라우터 서비스,  서비스에 있는 첫 부분 임포트들 복붙 가능
			![[Pasted image 20251205105444.png]]
	- CURSOR) @model.py 여기에 @train.csv (1) <train.csv 스키마 부분> 이 프로퍼티들의 게터 세터를 제작해줘.
	- GPT) 머신러닝에서 전처리 과정이 뭐야
		- 전처리(preprocessing)는 “학습이 잘되도록 데이터를 깨끗하고 모델 친화적으로 만드는 준비 작업”입니다.
	- CURSOR) @requrirements.txt@service.py 판다스, 넘파이, 사이킷런, 데이터셋, 아이스크림 라이브러리를 설치하도록 해줘
	- 앞으로 판다스 넘파이 사이킷은 항상 같이 만들어야 함
	- docker-compose up -d ml-service 로 mlservice만 컨테이너 띄움
	- CURSOR) @main.py 여기에서 @router.py 여기로 연결되는 코드를 작성해줘
	- CURSOR) @main.py 이것에 대한 스웨거를 줘
- 결론은 로컬호스트에 스웨거 띄우고, 포스트맨에서 앤드포인트로 데이터 잘 나오는지 확인
- 로컬호스트에서 데이터를 보려면 프론트 개발자가 디자인하고 오류 나는 걸 기다려야하니까, 원하는 서비스만 컨테이너화 해서 도커 돌리고, 앤드포인트를 포스트맨에 입력해서 데이터 잘 나오는지 확인할 것

- mlservice 의 app 밑에 datasets.py 파일 만들고 강사님 엑스에서 데이터셋 긁어옴
	- @datasets.py 인덴트를 수정해줘 --> 들여쓰기 에러 잡아주는 프롬프트

- 데이터 관련 용어
	- **DB** = 서비스 운영용 _실시간 데이터창고_ --> CRUD
	- **Dataset** = 분석·모델링용 _파일 묶음_ > 웨어하우스에서 일부분 발췌 -> @dataclass 데코레이터 사용(파이썬에서는 어노테이션이 아니라 데코레이터라고 함)
	- **Data Store (storage)** = 클라우드에서 데이터를 _넣어두는 모든 저장 공간(우산 개념)_
	- **Data Warehouse** = 여러 시스템의 데이터를 모아서 분석하기 위한 _대규모 중앙 분석 창고_
	- ~~(거의 안씀)**Data Mart** = DW 안에서 특정 부서/목적용으로 잘라낸 _소형 분석 창고_~~
- 역사기록처럼 온전한 히스토리로써 쌓아가는 것이 데이터 웨어하우스
- 데이터웨어하우스에서 분석을 위해 묶은 게 데이터셋

##### 코드 보면서 설명
- 파이썬에서는 { } 생략, 대신 콜론: 사용
- 어노테이션 대신 데코레이터라고 부름 (생긴 것은 @로 동일)
	- @dataclass : 데이터웨어하우스에서 일부분 발췌하는 데코레이터
	- @property : 필요한 부분만 읽게 하는 것
- '#' 은 주소
- _ 는 자바에서 private , 아무것도 안 쓰면 public
- str 은 자바에서 String
- 스트링은  ' ' 로 null 을 표현
- 게터는 안 쓰고 property 를 보면 알 수 있는거고 return이 있는 것
- 세터는 frame뒤에 세터를 쓰고 return이 없음
- -> 람다 있음. 결국 같다는 의미
- self는 this를 의미함. 컨텍스트를 갖고 있다는 거지
- pass 는 빈칸을 의미


- 데이터 프레임을 다룰 때 쓰는 클래스 이름이 pandas 판다스임
- 웨어하우스에서 셋을 먼저 뽑고 필요한걸 프레임으로 뽑아
- 데이터프레임은 데이터 셋 안에 있어야 하는 것

- 다음 두 줄을 사용하는 이유는, 위에껄로 뽑아와서 아래껄로 테스트하면서 훈련하겠다는 것 
	`_train: pd.DataFrame = None`
	`_test: pd.DataFrame = None`

- 타이타닉에서 탑승객 및 정보가 웨어하우스였고, 전처리과정에서 생존여부를 넣게 되면서 데이터셋을 만든거고 이 행위를 라벨링이라고 함
- 파라미터의 확률로 A->f(x) 에서 A들로 f(x)를 추론할 수 있겠다


컨 서 레 엔
라우서-서비스-모델   ->엔티티에 해당하는 게 없는이유는 웨어하우스에서 뽑아온건데 그 데이터 셋을 저장한다는 게 말이 안돼

----------
## 오후 실습

- 폴더 다시 다음처럼 바꿈
	![[Pasted image 20251205150153.png]]
	- 전처리 - 모델링 - 학습 - 후처리 - 제출 순서로 모든 파이썬은 기본 구조를 가짐
		- postprocessing을 evaluate로 바꿔줌. 위 구조가 점수화 될건데, 점수가 낮으면 후처리과정에서 다시 전처리로 돌아가서 반복하니까 후처리라기 보다는 평가에 가까움 
			![[Pasted image 20251205150543.png]]


- CRUD는 DB에서만 쓰는 말
- 지금처럼 DW나 DW에서 쓰는 건 ML임. 이것은 통계학에 근거
- DL 은 글자가 아닌 것에 대한 훈련을 의미함 (강아지냐 고양이냐, 주식이 오를까 내릴까)


- 0,1 로 나눌 수 있는 것 (적자일까 흑자일까)

- csv 에 있는 자료는 DS 이고, 이걸로 f(x)를 만들어. 이 때 f(x)를 모델이라고 함
- 모델은 결국 한 줄이다?
- 메소드는 서비스의 부분집합

1. 모델만들기
2. csv에서 ~가 라벨이야. 라고 알려주고 시작하면 좋은

-------------
## grade로 실습
- 일단 grade 폴더를 titanic 폴더랑 시블링으로 만들고, 그 안에 기본 구조에 해당하는 파일들 만들기. csv 파일도 넣기
		![[Pasted image 20251205174315.png]]
- @grade_router.py여기에 이것과 @main.py 이것과 연결하고 @grade.csv 이 데이터셋에서 상위 10개를 볼 수 있는 코드를 작성해줘
- @mlservice 이것만을 재빌드 및 재실행 해줘
- @grade 여기에서 상위 10개 항목을 보는 것을 포스트맨에서도 확인할 수 있게 URL을 줘