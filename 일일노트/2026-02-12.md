### 오류1
- 데이터 적재(BGE-M3) 후 올바르게 문서를 찾아 오는지 테스트
- IFRS, OECD 등 영어 원문에서 "Introduction”, “human capital”, “reporting”, “국제”, “지표” 같은 공통 표현이 많아서, “IFRS”, “OECD” 질문과도 의미적으로 가깝게 잡힘
- => 별도의 컬럼 타입을 두고 명확하게 찾아올 수 있도록 Btree 인덱스 추가

### 오류2
- ![[Pasted image 20260212094929.png]]
- Limit reached You've used all of your monthly storage allowance for this project.
[Review usage](https://console.neon.tech/app/org-misty-breeze-38235467/billing)
- 임베딩 벡터(1024차원)는 일반 텍스트보다 훨씬 무겁기 때문에, 8만 6천 건 정도면 딱 한계치에 도달할 양입니다.
- 현재 상태에서 **추가 적재는 불가능하지만, 이미 들어간 데이터를 활용해 로직을 완성하는 것은 가능**
- => DELETE FROM competency_anchor WHERE embedding IS NULL; 현재 11만 건 중 약 3만 건이 임베딩 없이 텍스트만 있는 상태입니다. 검색(RAG)에 활용할 수 없는 데이터이므로 과감히 지워 공간을 확보하세요.
- ![[Pasted image 20260212095953.png]]
- **영향:** 데이터 Insert 작업은 CPU와 메모리를 많이 소모합니다. 특히 수만 건 이상의 데이터를 한꺼번에 넣을 때, Free 플랜의 2 CU(computing unit)는 금방 병목 현상(Bottleneck)이 발생하여 처리 속도가 느려집니다. 16 CU까지 확장이 가능해지면 더 많은 연산을 동시에 처리할 수 있어 속도가 개선됩니다.
- **정적 할당 (Static):** 차가 밀리든 안 밀리든 무조건 톨게이트 입구를 2개만 열어두는 것입니다. 차가 없으면 낭비고, 차가 몰리면 엄청난 정체가 발생합니다. (Free 플랜의 낮은 제한과 비슷합니다.)
- **동적 할당 (Dynamic):** 평소에는 1~2개만 열어두다가, 명절처럼 차가 몰리면 순식간에 16개까지 입구를 늘리는 방식입니다. 차가 다시 줄어들면 비용 절감을 위해 다시 입구를 닫습니다.
- 두 요금제 모두 동적 할당이지만 문의 갯수가 달라서 `조금만 몰려도 금방 느려짐웬만한 부하는 순식간에 처리`

- ![[Pasted image 20260212101806.png]]
- **Anonymization** is available. Protect your users' personal data with static masking rules.
- **Anonymization (익명화):** 데이터를 누구인지 알 수 없게 만드는 과정입니다.
- **Static Masking (정적 마스킹):** 데이터베이스의 복사본(개발용, 테스트용, 분석용)을 만들 때, 원본 데이터의 형태는 유지하되 값만 가짜로 바꾸는 기술입니다.
- ![[Pasted image 20260212101958.png]]
- => `이미 적재된 건 수 테스트 , 레그 연동, 로컬에서 학습 시킴`

개념 
- ![[Pasted image 20260212115606.png]]
- 멀티모달(Multimodal)이 여기서 의미하는 것
- `모달(Modal) = 입력 종류 하나`
- 텍스트 모달: 문자만 (문장, 단어)
- 이미지 모달: 그림, 사진
- 음성 모달: 소리
- 영상 모달: 비디오
- 하나의 “입력 형태”를 한 가지 모달이라고 부릅니다.
- `멀티모달 = 여러 종류 입력을 동시에 이해·처리`
- 멀티모달 모델 = 한 번의 호출 안에서
- 텍스트 + 이미지(+ 필요하면 음성·영상 등)를 함께 입력으로 받고,
- 그걸 한 덩어리로 이해해서 답을 내는 모델.
- “이미지를 먼저 텍스트로 바꾼 뒤, 그 텍스트만 넣는” 방식은 멀티모달이 아님.
- 그건 “이미지 모달 → 텍스트 모달로 변환 후, 텍스트만 쓰는 것”입니다.
---
- `우리 맥락에서 말한 “멀티모달”`
- 멀티모달 LLM / Vision LLM
= 이미지 픽셀(또는 이미지 URL/바이트)과 텍스트를 같은 입력으로 받는 모델.
- 예:
- 사용자: “이 사진에 뭐가 보여?” + 이미지 1장
- 모델: 그 이미지를 직접 보고 + 질문 텍스트를 보고 → 한 번에 답 생성.
- 반대로
- “이미지 → 별도 Vision API로 캡션 생성 → 그 캡션 텍스트만 텍스트 전용 LLM에 넣기”
- 는 멀티모달이 아니라, “이미지 모달을 중간에 텍스트로 바꾼 뒤, 텍스트 모달만 쓰는” 구조입니다.
- `멀티모달 = 한 모델이 여러 종류 입력(텍스트 + 이미지 등)을 동시에 입력으로 받아서, 그걸 한꺼번에 이해하고 처리하는 방식`
- `모달 = 데이터가 전달되거나 표현되는 특정한 형태나 통로
- 여기서의 모델은 `제미나이`

- `그럼 모달은 반드시 모델을 갖는가?`
- **모달(Modality):** 모델이 없어도 존재함 (단순한 데이터의 형태).
- **멀티모달(Multi-modal):** **반드시 모델을 전제로 함.** 서로 다른 모달을 '동시'에 이해하고 '연결'하는 주체가 바로 모델이기 때문입니다.

- `멀티모달이 유리한 이유`
1. 속도: Vision 캡션 단계를 없애서 호출·단계가 줄고, 전체 지연이 짧아짐.
2. 품질: 모델이 이미지를 직접 보므로, “캡션으로 한 번 줄인 정보”보다 질문에 맞게 더 잘 이해함.
3. 구조 단순화: “이미지 → 캡션 → 텍스트 LLM” 파이프라인 대신 “이미지+텍스트 → 멀티모달 한 번”으로 정리됨.
4. UX: 사용자 입장에서는 “사진 넣으면 그걸 보고 답해 준다”에 가깝게 동작해서, 기대와 맞음.
5. 이미 Gemini 키 보유: 추가 비용 없이 전환만 하면 됨.

- `이미지 답변` : `Gemini가 이미지에서 텍스트(캡션) 추출 -> 그 문장으로 DB 검색 -> Gemini가 최종 답변
- 캡션 만들기 (이미지만 있거나 "[이미지 첨부]"일 때)
- get_image_caption_for_rag(images) → Gemini가 이미지에서 검색에 쓸 문장 추출
- 이 문장을 사용자 메시지이자 RAG 검색 쿼리로 사용 (user_text)
- RAG에서 DB 가져오기
- rag_node가 state["messages"]에서 마지막 사용자 메시지 내용을 쿼리로 씀
- 위에서 만든 캡션(또는 사용자가 입력한 텍스트)
- 이 쿼리로:
- vector_store (PGVector 등) 유사도 검색
- disclosure 테이블 검색
- competency_anchors 테이블 검색
- 찾은 문서들을 이어서 state["context"] 에 넣음 → 이게 “DB에서 가져온 내용”
-  답변 생성
- model_node에서 state["images"]가 있으면 Gemini 호출
- Gemini에 넘기는 값:
- user_text: 캡션 또는 사용자 입력
- images: 원본 이미지
- context: 위에서 RAG가 채운 DB 검색 결과 문자열
- `JSON + base64` : 한 번에 처리, 업로드 API 없이 채팅 한 번으로 메시지+이미지 전송. 클라이언트는 fetch 한 번, 서버는 엔드포인트 하나만 관리. -> 멀티 파트 사용하지 않은 이유.
- 단점 : 이미지를 학습 시킬 필요성이 있을때, 
- `지금 방식(멀티파트 + JSON 병행, 파일 미저장) 의 장단점`
- 장점: 표준에 가깝고, 전송/구현이 단순하며, 저장 없이 이미지·파일을 한 요청으로 처리할 수 있음.
- 단점: 메모리 사용·재사용성 제한, 이중 파싱·분기, 대용량 시 별도 제한과 설계가 필요함.
- ![[Pasted image 20260212145034.png]]
- `Fallback = 실패 대비용 대체 경로 / 대체 값 / 대체 시스템`
- 