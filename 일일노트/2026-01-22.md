- pgvertor -> neon DB 확장 이유 : 대원칙 - 
- persistance(영원히 저장해야 할 곳은 하나다) 저장소 = 스토리지는 하나여야 됨 
- temporary(캐시 메모리) 
- 레디스는 왜 아니냐? 영속성 저장소가 아니라서.
- 크로마 : 영속성을 갖지 않는다  = 가볍다. 
- pg(포스트그리)/verctor(백터스토어) -> 포스트그리 + vectorDB => 백터DB(온톨리지 : 추상적인 개념 - 대도서관 철학의 개념이 투영되면 온톨리지라고 부름)
- 임베딩값이 있으면 백터에 넣고 없으면 pg에 넣음
- 
# ### 1단계: 환경 확인

# 1. Python 경로 확인

cd C:\Users\kku10\OneDrive\문서\RAG

# 2. 필수 패키지 설치 확인

pip list | findstr "unsloth trl transformers datasets"

# 3. GPU 확인 (CUDA 사용 가능 여부)

python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"

---

### 2단계: 데이터 준비 확인

# 학습 데이터 경로 확인

python -c "from app.domain.spam.services.utils import get_data_dir; print(get_data_dir() / 'sft_dataset' / 'processed' / 'train.jsonl')"

# 데이터 파일 존재 여부 확인

dir app\data\sft_dataset\processed\train.jsonl

---

### 3단계: 모델 로딩 테스트 (가장 빠른 확인)

# 모델 로딩만 테스트 (학습 없이)

python -c "

from app.training.finetune_llama import LLaMATrainer

trainer = LLaMATrainer()

trainer.load_model()

print('✅ 모델 로딩 성공!')

"

---

### 4단계: 데이터 로딩 테스트

# 데이터 로딩 테스트

python -c "

from app.domain.spam.services.utils import load_jsonl, get_data_dir

from pathlib import Path

data_path = get_data_dir() / 'sft_dataset' / 'processed' / 'train.jsonl'

if data_path.exists():

    data = load_jsonl(data_path)

    print(f'✅ 데이터 로딩 성공: {len(data)}개')

    print(f'샘플: {data[0] if data else None}')

else:

    print(f'❌ 데이터 파일 없음: {data_path}')

"

---

### 5단계: 전체 파이프라인 테스트 (소규모)

# 1. 작은 데이터셋으로 테스트 (10개 샘플만)

python -c "

from app.domain.spam.services.utils import load_jsonl, get_data_dir

from pathlib import Path

import json

data_path = get_data_dir() / 'sft_dataset' / 'processed' / 'train.jsonl'

if data_path.exists():

    data = load_jsonl(data_path)

    # 처음 10개만 저장

    test_data = data[:10]

    test_path = Path('test_train.jsonl')

    with open(test_path, 'w', encoding='utf-8') as f:

        for item in test_data:

            f.write(json.dumps(item, ensure_ascii=False) + '\n')

    print(f'✅ 테스트 데이터 생성: {test_path} ({len(test_data)}개)')

"

# 2. 작은 데이터로 학습 테스트 (1 에포크, 작은 배치)

cd app\training

python finetune_llama.py --train_path ..\..\test_train.jsonl --num_epochs 1 --batch_size 2 --learning_rate 2e-4

---

### 6단계: 전체 학습 실행 (실제 데이터)

cd app\training

# 기본 설정으로 학습

python finetune_llama.py

# 또는 커스텀 설정

python finetune_llama.py \

    --num_epochs 3 \

    --batch_size 8 \

    --learning_rate 2e-4 \

    --max_seq_length 512

---

### 7단계: 학습된 모델 테스트

# 학습된 모델 로드 테스트

python -c "

from app.core.llm.providers.llama import LLaMAGate

# Fine-tuned 모델 경로 확인

from app.core.paths import get_fine_tuned_llama_dir

print(f'모델 경로: {get_fine_tuned_llama_dir() / \"adapters\" / \"final_model\"}')

# 모델 로드 테스트

gate = LLaMAGate()

result = gate.classify_spam({

    'subject': '테스트',

    'sender': 'test@example.com',

    'body': '스팸 테스트 메일입니다.'

})

print(f'✅ 추론 테스트 성공: {result}')

"