- 베이스 경로 - hf 로 전환 -> 
- `환경 독립성 (Portability)`
- 가장 큰 장점입니다. 로컬 경로(`base_models/...`)를 사용하면 협업하는 동료나 서버 환경마다 폴더 구조를 똑같이 맞춰야 하는 번거로움이 있었죠. 이제는 코드만 복사하면 어디서든(Colab, 클라우드 서버, 개인 PC) 즉시 실행 가능합니다.
- `버전 관리의 명확성`
- 로컬 경로는 그 안에 있는 파일이 수정되었는지 알기 어렵지만, HuggingFace ID를 쓰면 특정 리비전이나 태그를 명시할 수 있습니다.
- 기존: "내 컴퓨터에 있는 그 모델" (버전 확인 불가)
- 변경: "EXAONE 3.5 버전" (공식 배포 버전 보장)
- `자동 업데이트 및 캐시 최적화`
- `from_pretrained()` 함수가 알아서 캐시 디렉터리(`~/.cache/huggingface`)를 관리하므로, 모델 파일이 깨졌을 때 복구하기 쉽고 중복 다운로드도 방지됩니다.
- `코드의 간결함`
- 환경 변수(`EXAONE_MODEL_DIR`)를 따로 설정하거나 관리할 필요가 없어 코드가 훨씬 깨끗해졌을 겁니다.
- sentranceformer -> flagembedding 단일화 -> 네온 DB 데이터 용량 떄문에 pca(차원 축소) 고민했으나 차원의 이점을 살리기 위해서 걍 둠 -> 
- 로컬에서 학습으로 돌리거나 faiss 설치 해서 로컬 백터 DB 테스트 할 생각

- `flagembedding(라이브러리, 공식 docs 호환성)으로 통일`
- : SentenceTransformer(라이브러리) + MiniLM(모델) 대신 BGE-m3를 사용하는 이유: 다국어·긴 문서·1024차원 통일·RAG 품질”
- SentenceTransformer 설치 -> minilm(모델) 허깅페이스에서 코드에서 쓰는 순간 자동으로 가져와짐(별도로 pip install 안해도 자동 다운로드 되서 사용가능했던 것)
- flagembedding 먼저 설치 했으면  BGE-m3도 같은 방식으로 작동 되었을 텐데, flag로 전환이 나중에 이루어져서 pip bge-m3도 하고 flagembedding(라이브러리)도 설치하는 번거로운 일 발생. 

- `불필요하게 랭체인으로 임베딩 백터 관리했다가 랭그래프로 또 넘어가는 구조 개선`
- 네온 db 용량 초과로 2,000건의 제한을 두고  테스트
- `백터 DB -> faiss로 로컬에서 관리`
- `11만건 데이터 적재 후 테스트 완료`
- 
