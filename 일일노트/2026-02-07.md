- 임베딩 모델
- 공시기준에서 사용하게 될 임베딩 모델은 **전문 용어의 문맥 파악 능력**과 **한국어-영어 간의 교차 언어(Cross-lingual) 정렬 능력**이 가장 중요
- `BGE-m3 (Multilingual-Multitask-Multi-granularity)` : 현재 RAG(검색 증강 생성) 분야에서 가장 추천되는 오픈소스 모델입니다.
- **강점**: 한국어를 포함한 100개 이상의 언어를 지원하며, 짧은 문구부터 8,192 토큰의 긴 문서(ISO 표준 전체 본문 등)까지 한 번에 임베딩할 수 있습니다.
- 
- **공시 적합성**: ISO 30414의 영문 원문과 한국어 간의 의미적 거리를 매우 가깝게 연결해줍니다   
- 한줄 요약 : 간단한건 MiniLM으로도 충분하지만, 데이터가 길어지면 문서의 내용이 잘린채로 DB에 저장될 수 있고 제대로 매핑이 안될 수도 있어서 임베딩 모델을 따로 두는 것이 좋고 공시에 최적화 된게 `BGE-m3`이다

- 테스트용 MiniLM : sentencetransformer 제거 
- `FlagEmbedding`이 프로젝트의 미래에 더 적합한지 전략적으로 분석해 드립니다.
- ![[Pasted image 20260207182847.png]]
- 데이터베이스 마이그레이션에서 스쿼시(Squash)**는 단어 뜻 그대로 여러 개의 파일을 '하나로 꽉 짜서 합치는 것'을 의미
- `Disclosure = “문서 → 쪼개기 → 임베딩 → 저장” 같은 다단계 파이프라인이라 랭그래프로 오케스트레이션.`
- `Soccer = “구조화 데이터 저장 + 임베딩” 한 번에 처리하면 되니까 서비스 레이어만 사용.`
-  “공시기준 PDF는 disclosures 테이블에 적재하고,
- 라마/엑사원은 RAG 결과 + 프롬프트로 쓰고,
- 필요하면 나중에 분석 스킬/정책을 파인튜닝으로 보강한다”
- 1단계 (지금)
- 임베딩 모델(BGE-m3) 로 각종 공시 기준 PDF를 읽어와서
- 청크로 나누고 벡터로 만든 뒤
- disclosures 테이블에 적재한다.
  → 여기까지가 “공시 기준을 DB에 넣는” 단계.
- 그다음 학습은 라마와 엑사원 둘 다 대상이 될 수 있고,
- 그때 하는 게 파인튜닝으로 보강하는 것이다.
- 라마: 판단 정책/필터링 스타일
- 엑사원: 분석·보고 패턴, ISO 지표 해석 방식 등
- 이때 쓰는 “교재”는 disclosures에 적재된 공시 기준을 RAG로 가져온 데이터 + 그걸 활용한 예시/대화이고,
- “임베딩으로 disclosures에 공시 기준 적재 → (필요 시) 라마·엑사원 둘 다 파인튜닝으로 보강” 하는 구조가 맞고, 파인튜닝 보강할 때가 “나중에 라마/엑사원에게 학습시키는” 단계라고 보면 됩니다.
