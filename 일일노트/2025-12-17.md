- Rag(체인) = 파이프라인 - Plumber(배관공)
- 체인에서 서버 중간에 렝체인이 있다.
- 화면까지 있어야 완전한 RAG 
- 자바에서는 컨서레엔으로 작은거 부터 파이프라인 형성 
- RAG에서는 거대한 체인 올려놓고, 세밀사항 조정(인테리어)
- 체인이 돈 된다.(이런 회사로 감)
- https://www.redhat.com/ko/topics/ai/rag-vs-fine-tuning 
- 체인 패턴에 대한 설명, 뭐는 안좋아서 그래서 좋아서 블라블라
- RAG(껍데기)와 미세조정(fine-tuning) 디테일
- `RAG는 기반 LLM을 수정하지 않고`(그대로 가져옴) 이 작업을 수행하는 반면, 미세 조정(fine-tuning)은 LLM의 `가중치와 매개 변수`를 조정해야 합니다.
- 파운 데이션 모델(LLM 기반 모델) - Foundation Model
- LM 파운데이션 모델은 `transformer`
- LLM의 파운데이션 모델 `라마.`
- `내가 쓰는 파운데이션에 따라 정책이 달라짐.`
- LLaMA 조직도 검색하면 나오는 그림(나무위키)
- ![[Pasted image 20251217101354.png]]
- 라마는 메타꺼, 리액트도 메타 -> 거의 프론트 시장 잡음.
- MicroSoft - chatgpt 회사(우리만 쓸거야) -> 지는해 
- 모든 오픈 API 에는 구글이 있음. (백엔드 시장)
- 삼성이 구글하고 친함, 아마 우리도 구글쪽으로 갈껄? 
- => 이 프로젝트의 파운데이션 모델은 라마다. 코 알파카는 한국어가 프리트레인된 모델이다.
- 라마 : 모델에서의 프레임워크, 코알파카(한국어)
- RAG는 데이터 리포지토리, 텍스트 컬렉션, 기존 `도큐멘테이션` (pg백터)
- 파인튜닝은  PEFT인데, 어떤건 Lora쓰고 어떤건 QLoRa 썼냐.
- 팀의 기술 역량 수준 코딩 및 아키텍처 기술이 필요
- https://www.databricks.com/kr/glossary/fine-tuning
- 기존의 사전 훈련된 대형 언어 모델 (LLM)을 수정하는 것이 처음부터 새로운 모델을 훈련시키는 것보다 더 쉽고 비용이 적게 든다는 것을 발견했습니다.
- **PEFT (Parameter-Efficient Fine-Tuning)**
`PEFT (Parameter-Efficient Fine-Tuning)`는 대규모 사전 훈련된 모델을 특정 작업에 적응시키면서 계산 자원과 저장 요구 사항을 최소화하기 위해 설계된 기법들의 집합입니다. 이 접근법은 제한된 자원을 가진 응용 프로그램이나 여러 파인튜닝 작업이 필요한 응용 프로그램에 유익합니다. PEFT 방법들, 예를 들어 저랭크 적응(`LoRA`)과 `어댑터 기반 파인튜닝`은, `전체 모델을 업데이트`하는 대신 훈련 가능한 `매개변수의 수`를 적게 만들어 작동합니다. `어댑터` 계층은 PEFT의 `핵심 구성 요소`로, 사전 훈련된 모델의 각 계층에 삽입되는 경량, 훈련 가능한 모델입니다. 
=> 전체는 그대로 두고 필요한 부분만 꽂아넣든, 수정하든 하겠다. => 어뎁터 220v 맞는거 끼우는거 마냥. => 모델에 붙임 `전체 아키텍처 건들지 않고 특정부분에 인풋값을 넣는거.`
- 양자화 저랭크 적응(QLoRA) Adapter는 로라와 큐로라가 있는데 큐로라는 양자화 되있다.
- PEFT 파인튜닝하기 위한 기술, 파라미터 수를 크게 줄이는 방법
- rtx 3050에서 코알파카를 패프트로 학습하려고 해.
- 팀꺼는 라마로.
- 
- 그림 : freeze, 전체 중 일부분은 얼려두고 나머지 파라미터만 활성화 하겠다.
- 행렬의 차원(파라미터)을 축소한다. 1억차원이다 -> 이러면 1억 차원인거.
- 풀파인튜닝을 줄인게 양자화
- 양자화 : 실수형에서 정수형으로 줄인다. 32비트 짜리가 8비트로 줄어둔다.
- 줄어드니까 효율성은 늘어나는데 정확도는 늘어남.
- 로라 필요한 것만 두고 나머지는 프린트
- 큐로라는 일부만 하니까 
- Lora(Rank - 차원의 수) 파라미터(컬럼,피처,변수)의 숫자
- 파라미터 수를 줄인다.
- 양자와 큐로라 -> 기본적으로 실수인데 정수로 줄인다.
- 실수 1.4가 있으면 1쪽에 붙이고 치운다.
- 묘목. 다른곳에 옮기면 죽으니까
- 모델 훈련시키는 훈련장 실제 작동은 .com과 똑같은 환경으로 훈련장을 만들면
- rag를 fastAPI로 감싸서 .com과 같은 환경으로 맞춘다.
-  
- from:LangChainAI fastapi
- ![[Pasted image 20251217145035.png]]
- RAG Pipeline Guide Learn to build production-ready RAG systems using Qdrant vector DB, FastAPI, and LangChain's LCEL for sophisticated retrieval chains. Key features: - Async vector search - Type-safe FastAPI endpoints - LCEL RAG pipelines Start building better RAG systems!  
- 
- https://blog.futuresmart.ai/comprehensive-guide-to-qdrant-vector-db-installation-and-setup
- 
- qdran - JPA
- 

